#Gap analysis
#Based on Phaseolus study (Ramirez-Villegas et al., 2010)
#J. Ramirez 
#CIAT
#March 2012

#-------------------------------------------------
# Run outside linux, only when new code is available
# cd /curie_data2/ncastaneda/code/gap-analysis-cwr/gap-analysis/gap-code
# cp * /curie_data2/ncastaneda/gap-analysis/gap_[crop_name]/_scripts
#-------------------------------------------------
#####################################################################

stop("Warning: do not run the whole thing")

crop <- "avena" #change according to the coded name
#basic stuff - where is the code
src.dir <- paste("/curie_data2/ncastaneda/gap-analysis/gap_",crop,"/_scripts",sep="") # !!! change accordingly !!!
gap.dir <-"/curie_data2/ncastaneda/gap-analysis" # !!! change accordingly !!!

#crop details
crop_dir <- paste(gap.dir,"/gap_",crop,sep="")

if (!file.exists(crop_dir)) {dir.create(crop_dir)}
setwd(crop_dir)

#basic stuff - creating folders
biomod <- paste(crop_dir,"/biomod_modeling",sep=""); if (!file.exists(biomod)) {dir.create(biomod)}

figs <- paste(crop_dir,"/figures",sep=""); if (!file.exists(figs)) {dir.create(figs)}

msks <- paste(crop_dir,"/masks",sep=""); if (!file.exists(msks)) {dir.create(msks)}
rm(msks)
 
narea <- paste(biomod,"/native-areas",sep=""); if (!file.exists(narea)) {dir.create(narea)}

# polys <- paste(narea,"/polyshps",sep=""); if (!file.exists(polys)) {dir.create(polys)}

ascis <- paste(narea,"/asciigrids",sep=""); if (!file.exists(ascis)) {dir.create(ascis)}

#== prepare taxonomic names for the analysis ==#
# source(paste(src.dir,"/000.fixTaxNames.R",sep=""))

#== compare germplasm vs. total records==#
source(paste(src.dir,"/01.countRecords.R",sep=""))

#== split H/G occurrences ==#
occ <- read.csv(paste("./occurrences/",crop,"_all.csv",sep=""))
occ <- occ[which(!is.na(occ$lat)),]
occ <- occ[which(!is.na(occ$lon)),]

h <- occ[which(occ$H==1),]
g <- occ[which(occ$G==1),]

write.csv(h,paste("./occurrences/",crop,"_h.csv",sep=""),quote=F,row.names=F)
write.csv(g,paste("./occurrences/",crop,"_g.csv",sep=""),quote=F,row.names=F)
write.csv(occ,paste("./occurrences/",crop,".csv",sep=""),quote=F,row.names=F)

#== samples densities comparison ==#
source(paste(src.dir,"/02.splitHG.R",sep=""))

#== prepare masks ==#
# source(paste(src.dir,"/000.prepareMasks.R",sep=""))
#set climate dir
#env_dir <- "C:/Users/ncp148/Documents/_geodata/bioclim/bio_10m_esri"
env_dir <- "/curie_data2/ncastaneda/geodata/bio_2_5m" # !!! change accordingly !!!
# msks <- paste(crop_dir,"/masks",sep="")
# 
# x <- createMasks(msks,env_dir)

#== crop climate data to extent of interest==#
#source(paste(src.dir,"/000.ExtractVariables.R",sep=""))
#x <- maskVariables(crop_dir,env_dir)

#== create SWD occurrence files ==#
source(paste(src.dir,"/001.createSWD.R",sep=""))

occ_dir <- paste(crop_dir,"/occurrences",sep="")
swd_dir <- paste(crop_dir,"/swd",sep="")
if (!file.exists(swd_dir)) {dir.create(swd_dir)}

sample_file = paste(crop,".csv", sep="")

x <- extractClimates(input_dir=occ_dir,sample_file=sample_file,env_dir=env_dir,
                     env_prefix="bio_",env_ext="",lonfield="lon",
                     latfield="lat",taxfield="Taxon",output_dir=swd_dir)

#== preparing kernel density files ==#
# source(paste(src.dir,"/000.kernelDensity.R", sep="")) NEEDS TO BE FIXED!

#== splitting the occurrence files for biomod==# THIS NEEDS TIME!
# source(paste(src.dir,"/003.createOccurrenceFilesBiomod.R",sep=""))
# oDir <- paste(crop_dir,"/biomod_modeling/occurrence_files",sep="")
# if (!file.exists(oDir)) {dir.create(oDir)}
# x <- createOccFilesBio(occ=paste(crop_dir,"/swd/occurrences_swd_ok.csv",sep=""), 
#                     taxfield="Taxon", outDir=oDir, env.dir=paste(crop_dir, "/biomod_modeling/current-clim", sep=""))

#== splitting the occurrence files ==#
source(paste(src.dir,"/003.createOccurrenceFiles.R",sep=""))
oDir <- paste(crop_dir,"/occurrence_files",sep="")
if (!file.exists(oDir)) {dir.create(oDir)}
x <- createOccFiles(occ=paste(crop_dir,"/swd/occurrences_swd_ok_kernel.csv",sep=""), 
                    taxfield="Taxon", outDir=oDir)

#== prepare native areas ==#
source(paste(src.dir,"/004.createNARasters.R",sep=""))

#== making the pseudo-absences ==#
source(paste(src.dir,"/002.selectBackgroundArea.R",sep=""))
fList <- list.files("./occurrence_files",pattern=".csv")

MaxModDir <- paste(crop_dir,"/maxent_modeling",sep="")
if (!file.exists(MaxModDir)) {dir.create(MaxModDir)}

bkDir <- paste(crop_dir,"/maxent_modeling/background",sep="")
if (!file.exists(bkDir)) {dir.create(bkDir)}

for (f in fList) {
  cat("Processing",paste(f),"\n")
  iFile <- paste("./occurrence_files/",f,sep="")
  oFile <- paste("./maxent_modeling/background/",f,sep="")
  x <- selectBack(occFile=iFile, outBackName=oFile, 
                  msk=paste(gap.dir,"/_backgroundFiles/backselection.asc",sep=""), 
                  backFilesDir=paste(gap.dir,"/_backgroundFiles/",sep=""))
}

#== perform the maxent modelling in parallel ==#
source(paste(src.dir,"/005.modelingApproach.R",sep=""))
GapProcess(inputDir=crop_dir, OSys="linux", ncpu=3, j.size="-mx8192m")

#== summarise the models metrics ==#
source(paste(src.dir,"/006.summarizeMetricsThresholds.R",sep=""))
x <- summarizeMetrics(idir=crop_dir)

#== calculate area with SD<0.15 (aSD15) ==#
source(paste(src.dir,"/007.calcASD15.R",sep=""))
x <- summarizeASD15(idir=crop_dir)

#select which taxa are of use for species richness
#get the following modelling metrics:
# a. 25-fold average test AUC (ATAUC)
# b. 25-fold stdev of test AUC (STAUC)
# c. proportion of potential distribution with SD>15 (ASD15)

#== isValid==1 if ATAUC>0.7, STAUC<0.15, ASD15<10% ==#
acc <- read.csv(paste(crop_dir,"/maxent_modeling/summary-files/accuracy.csv",sep=""))
asd <- read.csv(paste(crop_dir,"/maxent_modeling/summary-files/ASD15.csv",sep=""))

for (spp in acc$SPID) {
  cat("Processing taxon",paste(spp),"\n")
  
  #getting the quality metrics
  atauc <- acc$TestAUC[which(acc$SPID==spp)]
  stauc <- acc$TestAUCSD[which(acc$SPID==spp)]
  asd15 <- asd$rateThresholded[which(asd$taxon==paste(spp))]
  
  #putting everything onto a row for appending
  row_res <- data.frame(Taxon=paste(spp),ATAUC=atauc,STAUC=stauc,ASD15=asd15,ValidModel=NA)
  
  #checking if any is na and correcting consequently
  if (is.na(atauc)) {atauc <- 0}
  if (is.na(stauc)) {stauc <- 1}
  if (is.na(asd15)) {asd15 <- 100}
  
  #reporting model quality
  if (atauc>=0.7 & stauc<=0.15 & asd15<=10) {
    row_res$ValidModel <- 1
  } else {
    row_res$ValidModel <- 0
  }
  
  #appending everything
  if (spp == acc$SPID[1]) {
    res_all <- row_res
  } else {
    res_all <- rbind(res_all,row_res)
  }
  
}
write.csv(res_all,paste(crop_dir,"/maxent_modeling/summary-files/modelsMets.csv",sep=""),quote=F,row.names=F)

#== create taxa for spp richness table ==#
table_base <- read.csv(paste(crop_dir,"/sample_counts/sample_count_table.csv",sep=""))
table_base <- data.frame(Taxon=table_base$TAXON)
table_base$IS_VALID <- NA

#== reading tables ==#
samples <- read.csv(paste(crop_dir,"/sample_counts/sample_count_table.csv",sep=""))
model_met <- read.csv(paste(crop_dir,"/maxent_modeling/summary-files/modelsMets.csv",sep=""))

names(model_met)[1]="TAXON"
table_base <- samples

for (spp in table_base$TAXON) {
  cat("Processing species",paste(spp),"\n")
  
  #modelling metrics
  if(sum(model_met$TAXON==paste(spp))==0){atauc <- NA
                                          stauc <- NA
                                          asd15 <- NA
                                          isval <- NA}else{
                                            atauc <- model_met$ATAUC[which(model_met$TAXON==paste(spp))]
                                            stauc <- model_met$STAUC[which(model_met$TAXON==paste(spp))]
                                            asd15 <- model_met$ASD15[which(model_met$TAXON==paste(spp))]
                                            isval <- model_met$ValidModel[which(model_met$TAXON==paste(spp))]}
  
  table_base$ATAUC[which(table_base$TAXON==paste(spp))] <- atauc
  table_base$STAUC[which(table_base$TAXON==paste(spp))] <- stauc
  table_base$ASD15[which(table_base$TAXON==paste(spp))] <- asd15
  table_base$IS_VALID[which(table_base$TAXON==paste(spp))] <- isval
  
}

table_base=table_base[c(1,11)]

table_base$IS_VALID[which(is.na(table_base$IS_VALID))]<-0

write.csv(table_base,paste(crop_dir,"/summary-files/taxaForRichness.csv",sep=""),row.names=F,quote=F)

rm(table_base, samples, model_met)

#== Filtering occurrences by native area ==#
source(paste(src.dir,"/000.filterOccFilesByNArea.R",sep=""))
OccFilterNArea (crop_dir)

#== calculate size of distributional range ==#
source(paste(src.dir,"/008.sizeDR2.R",sep=""))
sizeDRProcess(inputDir=crop_dir, ncpu=2, crop=crop)

#== summarise area files ==#
source(paste(src.dir,"/008.summarizeDR.R",sep=""))
summarizeDR(crop_dir)

#== reclassify PCA raster files ==#
clim <- paste(crop_dir,"/biomod_modeling/current-clim",sep="")

pca_rclass <- paste(clim,"/pca_result_reclass",sep="")
dir.create(pca_rclass)

for (i in 1:2) {
  cat("\nVariable",i,"\n")
  rs <- raster(paste(clim,"/pca_result_raw/pc_",i,".asc",sep=""))
  rs_res <- rs
  
  mx <- max(rs[],na.rm=T)
  mn <- min(rs[],na.rm=T)
  intval <- (mx-mn)/22
  brks <- seq(mn,mx,by=intval)
  
  for (cls in 1:20) {
    cat(cls," ")
    if (cls!=20) {
      rs_res[which(rs[]>=brks[cls] & rs[]<brks[cls+1])] <- cls
    } else {
      rs_res[which(rs[]>=brks[cls] & rs[]<=brks[cls+1])] <- cls
    }
  }
  cat("\n")
  rs_res <- writeRaster(rs_res,
                        paste(clim,"/pca_result_reclass/pc_r_",i,".asc",sep=""),
                        format='ascii')
#   plot(rs_res)
  rm(rs_res); g=gc(); rm(g)
  }

#== calculate environmental distance of distributional range ==#
source(paste(src.dir,"/009.edistDR.R",sep=""))
x <- summarizeDR_env(crop_dir)

#== calculate species richness ==#
source(paste(src.dir,"/010.speciesRichness2.R",sep=""))
x <- speciesRichness_alt(bdir=crop_dir)

#== create the priorities table ==#
#1. SRS=GS/(GS+HS)*10
table_base <- read.csv(paste(crop_dir,"/sample_counts/sample_count_table.csv",sep=""))
table_base <- data.frame(Taxon=table_base$TAXON)
table_base$HS <- NA; table_base$HS_RP <- NA
table_base$GS <- NA; table_base$GS_RP <- NA
table_base$TOTAL <- NA; table_base$TOTAL_RP <- NA
table_base$ATAUC <- NA; table_base$STAUC <- NA; table_base$ASD15 <- NA; table_base$IS_VALID <- NA
table_base$SRS <- NA; table_base$GRS <- NA; table_base$ERS <- NA
table_base$ERTS <- NA; table_base$FPS <- NA; table_base$FPCAT <- NA

#== reading specific tables ==#
samples <- read.csv(paste(crop_dir,"/sample_counts/sample_count_table.csv",sep=""))
model_met <- read.csv(paste(crop_dir,"/maxent_modeling/summary-files/modelsMets.csv",sep=""))
rsize <- read.csv(paste(crop_dir,"/maxent_modeling/summary-files/areas.csv",sep=""))
edist <- read.csv(paste(crop_dir,"/maxent_modeling/summary-files/edist.csv",sep=""))

names(model_met)[1]="TAXON"
names(rsize)[1]="TAXON"
names(edist)[1]="TAXON"
#spp=samples$TAXON
table_base <- samples

#== read principal components weights and scale them to match 1 ==#
#!!!!!!
w_pc1 <- 0.7
w_pc2 <- 0.3

for (spp in table_base$TAXON) {
  cat("Processing species",paste(spp),"\n")
  
  #sampling and SRS
  hs <- samples$HNUM[which(samples$TAXON==paste(spp))]
  hs_rp <- samples$HNUM_RP[which(samples$TAXON==paste(spp))]
  gs <- samples$GNUM[which(samples$TAXON==paste(spp))]
  gs_rp <- samples$GNUM_RP[which(samples$TAXON==paste(spp))]
  total <- samples$TOTAL[which(samples$TAXON==paste(spp))]
  total_rp <- samples$TOTAL_RP[which(samples$TAXON==paste(spp))]
  srs <- gs/total*10
  
  table_base$HS[which(table_base$TAXON==paste(spp))] <- hs
  table_base$HS_RP[which(table_base$TAXON==paste(spp))] <- hs_rp
  table_base$GS[which(table_base$TAXON==paste(spp))] <- gs
  table_base$GS_RP[which(table_base$TAXON==paste(spp))] <- gs_rp
  table_base$TOTAL[which(table_base$TAXON==paste(spp))] <- total
  table_base$TOTAL_RP[which(table_base$TAXON==paste(spp))] <- total_rp
  table_base$SRS[which(table_base$TAXON==paste(spp))] <- srs
    
  #modelling metrics
  if(sum(model_met$TAXON==paste(spp))==0){atauc <- NA
                                          stauc <- NA
                                          asd15 <- NA
                                          isval <- NA}else{
                                            atauc <- model_met$ATAUC[which(model_met$TAXON==paste(spp))]
                                            stauc <- model_met$STAUC[which(model_met$TAXON==paste(spp))]
                                            asd15 <- model_met$ASD15[which(model_met$TAXON==paste(spp))]
                                            isval <- model_met$ValidModel[which(model_met$TAXON==paste(spp))]}
  
  table_base$ATAUC[which(table_base$TAXON==paste(spp))] <- atauc
  table_base$STAUC[which(table_base$TAXON==paste(spp))] <- stauc
  table_base$ASD15[which(table_base$TAXON==paste(spp))] <- asd15
  table_base$IS_VALID[which(table_base$TAXON==paste(spp))] <- isval
  
  #grs
  g_ca50 <- rsize$GBSize[which(rsize$TAXON==paste(spp))]
  
  if(sum(rsize$TAXON==paste(spp))==0){
    drsize=NA
    grs=NA
  } else {
    if (isval==1) {
      drsize <- rsize$DRSize[which(rsize$TAXON==paste(spp))]
    } else {
      drsize <- rsize$CHSize[which(rsize$TAXON==paste(spp))]
    }
    grs <- g_ca50/drsize*10
    
    if (!is.na(grs)) {
      if (grs>10) {grs <- 10}
    }
  }
  table_base$GRS[which(table_base$TAXON==paste(spp))] <- grs
  
  #ers
  if(sum(edist$TAXON==paste(spp))==0){
    ecg_ca50_pc1=NA
    ecg_ca50_pc2=NA
    dr_pc1=NA
    dr_pc2=NA
    ers_pc1=NA
    ers_pc1=NA
    ers=NA
    } else {
      ecg_ca50_pc1 <- edist$GBDist.PC1[which(edist$TAXON==paste(spp))]
      ecg_ca50_pc2 <- edist$GBDist.PC2[which(edist$TAXON==paste(spp))]
      if(isval==1){
        dr_pc1 <- edist$DRDist.PC1[which(edist$TAXON==paste(spp))]
        dr_pc2 <- edist$DRDist.PC2[which(edist$TAXON==paste(spp))]
        
      } else {
        dr_pc1 <- edist$CHDist.PC1[which(edist$TAXON==paste(spp))]
        dr_pc2 <- edist$CHDist.PC2[which(edist$TAXON==paste(spp))]
        
      }
                 
      ers_pc1 <- ecg_ca50_pc1/dr_pc1*10
      if (!is.na(ers_pc1)) {
        if (ers_pc1 > 10) {ers_pc1 <- 10}
      }
      ers_pc2 <- ecg_ca50_pc2/dr_pc2*10
      if (!is.na(ers_pc2)) {
        if (ers_pc2 > 10) {ers_pc2 <- 10}
      }
      
      ers <- ers_pc1*w_pc1 + ers_pc2*w_pc2
      if (!is.na(ers))
        if (ers > 10) {ers <- 10}
    }
    table_base$ERS[which(table_base$TAXON==paste(spp))] <- ers
  
  #Final priority score
  if (gs==0) {
    fps <- 0
  } else if (hs==0 & gs<10) {
    fps <- 0
  } else {
    fps <- mean(c(srs,grs,ers),na.rm=T)
  }
  table_base$FPS[which(table_base$TAXON==paste(spp))] <- fps
  
  if (fps>=0 & fps<=3) {
    fpcat <- "HPS"
  } else if (fps>3 & fps<=5) {
    fpcat <- "MPS"
  } else if (fps>5 & fps<=7.5) {
    fpcat <- "LPS"
  } else {
    fpcat <- "NFCR"
  }
  table_base$FPCAT[which(table_base$TAXON==paste(spp))] <- fpcat
}

table_base=table_base[c(1,6:20)]

if (!file.exists(paste(crop_dir,"/priorities",sep=""))) {
  dir.create(paste(crop_dir,"/priorities",sep=""))
}

table_base$IS_VALID[which(is.na(table_base$IS_VALID))]<-0

write.csv(table_base,paste(crop_dir,"/priorities/priorities.csv",sep=""),row.names=F,quote=F)

#== calculate distance to populations ==#
source(paste(src.dir,"/011.distanceToPopulations2.R",sep=""))
ParProcess(crop_dir, ncpu=3)

#== calculate final gap richness ==#
source(paste(src.dir,"/012.gapRichness2.R",sep=""))
x <- gapRichness(bdir=crop_dir)

#== verify if gap map is available for each taxon ==#
priFile <- read.csv(paste(crop_dir, "/priorities/priorities.csv", sep=""))
newpriFile <- priFile
newpriFile$MAP_AVAILABLE <- NA

spList <- priFile$TAXON

for (spp in spList){
  fpcat <- priFile$FPCAT[which(priFile$TAXON==paste(spp))]
  if(file.exists(paste(crop_dir, "/gap_spp/", fpcat, "/", spp, ".asc.gz", sep=""))){
    newpriFile$MAP_AVAILABLE[which(newpriFile$TAXON==paste(spp))] <- 1
  } else {
    newpriFile$MAP_AVAILABLE[which(newpriFile$TAXON==paste(spp))] <- 0
  }
}

write.csv(newpriFile, paste(crop_dir, "/priorities/priorities.csv", sep=""), row.names=F, quote=F)
rm(newpriFile)

#== getting maps and figures ==#
source(paste(src.dir,"/013.mapsAndFigures.R",sep=""))

#== ensuring access to folders ==#
system(paste("chmod", "-R", "777", crop_dir))
